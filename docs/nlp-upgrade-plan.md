# NLP 기반 AI 인사이트 고도화 제안

## 현행 구조 요약 (왜 "NLP"가 아닌가?)
- `backend/app/services/analysis_service.py`: 기술적 지표 계산 + **조건문/문자열 포매팅** 기반 템플릿 문구 생성.
- `/api/stocks/{symbol}/decision-insight`: 지표 상태에 맞는 문구를 고르는 **규칙 엔진**을 호출해 프런트 `AiAnalysisPanel`에서 표시.
- **부족한 점**: 통계·ML·LLM 기반 언어 이해/생성을 쓰지 않으므로, 문장 다양성·맥락 적응력이 낮고 종목별 뉘앙스 반영이 어렵습니다. 실제 NLP AI라기보다 룰 기반 텍스트 매퍼에 가깝습니다.

## 고도화 목표
규칙 기반 텍스트 조립을 **생성형/분류형 NLP 모델**로 대체하거나 보완해, 종목별 맥락과 지표 변화를 더 자연스럽게 설명하는 것을 목표로 합니다.

## 단계별 접근
1. **프롬프트/템플릿 기반 LLM 생성**
   - 모델: OpenAI GPT, Claude, Llama 등 한국어 지원 LLM API.
   - 입력: 심볼/시장 메타, 가격·지표 스냅샷(SMA20/60, 모멘텀, HV20/ATR, MDD, Bollinger, MACD, RSI, 거래량 비율, 투자심리도, VKOSPI), 예측 밴드 요약, 정확도(MAPE/RMSE).
   - 출력: 
     - 핵심 브리핑(추세/모멘텀/리스크/밴드/정확도 요약)
     - 행동 제안(Buy/Hold/Sell 근거 2~3줄)
     - 모니터링 포인트(향후 주시 이벤트 2~3개)
   - 구현 포인트: 
     - 프롬프트에 **지표별 의미·해석 기준**을 안내해 일관된 톤 유지.
     - 응답 길이·형식을 JSON schema(예: pydantic)로 강제하거나 `function_call`/`tool_call` 스타일로 파싱.

2. **지표 상태 분류 + 텍스트 생성 하이브리드**
   - 분류기: LightGBM/로지스틱으로 `trend_state`(상승/중립/하락), `vol_state`(저/중/고) 등 라벨 예측 후, 소규모 템플릿이나 LLM 프롬프트에 라벨만 넘겨 더 짧은 프롬프트로 생성 비용을 절감.
   - 라벨 학습 데이터: 과거 지표 스냅샷 + 사람 레이블 혹은 규칙 기반 초기 라벨로 준지도 학습.

3. **파인튜닝/지시형 미세조정(선택)**
   - 도메인 코멘트가 많은 경우, Llama-3, Zephyr 등 한국어 가능한 모델을 LoRA/QLoRA로 파인튜닝해 사내 호스팅.
   - 데이터: (입력 지표 → 요약·행동 제안) 페어를 수집해 지도 학습. 민감 데이터는 비식별 처리 후 사내용.

4. **알림/모니터링 지능화**
   - 규칙: 변동성 급등, 밴드 이탈, 거래량 스파이크, VKOSPI 급등 같은 이벤트 감지기를 유지하되,
   - NLP: 이벤트 묘사 + 향후 시나리오를 LLM이 생성하도록 위임해 종목 특화 코멘트 제공.

5. **품질·비용·지연 관리**
   - 캐싱: 동일 심볼/지표 스냅샷에 대한 응답을 Redis에 캐시.
   - 레이트 리밋: 백엔드 라우터에서 사용자/토큰 단위 제한.
   - 토큰 절약: 숫자·지표를 요약 JSON으로 LLM에 전달하고, 지표 설명은 시스템 프롬프트에만 고정.

6. **안전성·규제 대응**
   - 면책: 응답 앞/뒤로 투자 자문이 아님을 명시.
   - 금칙어/금융 규제 필터: 특정 표현(확정 수익 등) 금지 리스트를 후처리.

## 적용 흐름 예시
1) **지표 스냅샷 준비**: 기존 `analysis_service`에서 계산한 SMA/모멘텀/HV20/ATR/MDD/Bollinger/MACD/RSI/거래량/심리/VKOSPI + 예측 밴드·정확도 요약을 JSON으로 정리.
2) **LLM 호출**: 시스템 프롬프트에 톤·금칙어·형식을 고정하고, 사용자/툴 프롬프트로 지표 JSON을 전달해 핵심 브리핑·행동 제안·모니터링 포인트를 생성.
3) **검증/정규화**: pydantic 스키마로 응답 구조·필드 타입을 검증하고, 실패 시 규칙 기반 문구로 폴백.
4) **캐싱/레이트리밋**: 동일 스냅샷 결과 캐시, 사용자별 호출 제한으로 비용/지연 관리.
5) **프런트 표출**: `AiAnalysisPanel`은 `mode=rule|llm|hybrid`에 따라 적절한 응답 블록을 받아 카드·배지·알림으로 렌더링.

## 샘플 프롬프트 스케치
```
시스템: "너는 한국어 금융 어드바이저다. 확정 수익/투자 권유 표현은 피하고, 최대 3문단으로 간결히 요약한다. 아래 JSON 필드를 해석해 브리핑을 작성하라."
사용자: {
  "symbol": "005930.KS",
  "price": 72100,
  "change_pct": 1.8,
  "indicators": {
    "sma20": 70500, "sma60": 68900,
    "momentum20_pct": 3.2,
    "hv20": 18.4, "atr_pct": 1.9,
    "mdd_pct": -8.5,
    "bollinger_pos": 0.62,
    "macd_hist": 0.14, "rsi": 58,
    "volume_ratio": 1.3,
    "sentiment10_up_pct": 70,
    "vkospi": 21
  },
  "forecast": {"upper": 76000, "lower": 67000, "horizon_days": 63},
  "accuracy": {"mape": 11.8, "rmse": 2510}
}
assistant: 핵심 브리핑, 행동 제안 2가지, 모니터링 포인트 2가지, 신뢰도·변동성 한줄 근거를 JSON으로 응답.
```

## 운영시 체크해야 할 리스크
- **비용/지연**: LLM 호출 빈도와 캐시 정책을 조정하고, SLA가 필요한 경우 규칙 기반 모드로 자동 전환.
- **금융 규제**: 면책·금칙어 필터를 사전/사후에 모두 적용, 로그에 입력/출력을 함께 저장해 사후 감사 가능하도록 구성.
- **데이터 프라이버시**: 내부 데이터(거래내역 등)를 투입할 경우 비식별 처리 후 전달하고, 외부 API 전송 금지 설정을 검토.

## 아키텍처 스케치
- 서비스 계층: `analysis_service.py`에 LLM 클라이언트 래퍼 추가 (`llm_client.generate_insight(snapshot)` 등).
- 설정: `.env`에 LLM API 키, 모델명, 타임아웃, 캐시 TTL.
- 백엔드 라우터: `/decision-insight`에서 규칙/LLM 혼합 모드 선택 가능하도록 `mode` 쿼리(예: `mode=hybrid|llm|rule`).
- 프런트: AiAnalysisPanel에서 `mode` 토글(예: "스탠다드"/"LLM 베타")을 제공하고, LLM 응답 구조를 표시.

## 점진적 마이그레이션 체크리스트
- [ ] 규칙 기반 결과를 유지한 채 LLM 생성 결과를 병렬로 반환하는 실험 플래그 추가
- [ ] JSON 스키마 강제(prompt + pydantic 검증)로 응답 구조 안정화
- [ ] 캐시/레이트리밋 도입, 에러 시 규칙 기반 결과로 폴백
- [ ] 소규모 사용자 그룹 A/B 테스트로 응답 품질·지연 측정
- [ ] 운영 가드레일(금칙어 필터·면책문구) 적용 후 전체 롤아웃

## 관련 파일 경로
- 백엔드 서비스: `backend/app/services/analysis_service.py`
- API 라우터: `backend/app/routers/stocks.py` (`/api/stocks/{symbol}/decision-insight`)
- 프런트 소비: `src/components/analysis/AiAnalysisPanel.jsx`, `src/api/stockApi.js`
